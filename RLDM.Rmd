---
title: "The reinforcement learning diffusion model"
---

```{r echo=TRUE, message=FALSE, warning=FALSE}
rm(list = ls())
library(tidyverse)
library(dfoptim)
library(rtdists)
library(rstan)
library(bayesplot)
```

First, we need to create some stimuli for the reinforcement learning task. I am going to recreate the experiment we used in [our RLDM paper](https://link.springer.com/article/10.3758/s13423-018-1554-2):

```{r echo=TRUE, message=FALSE, warning=FALSE}
generate_RL_stimuli <- function (n_trials, trial_types, mean_options, sd_options) {
  # n_trials_block : Number of trials per learning session.
  # n_blocks : Number of learning session per participant.
  # n_participants : Number of participants.

  # trial_types : List containing possible pairs of options.
  # E.g., in the original experiment: c('1-2', '1-3', '2-4', '3-4').
  # It is important that they are separated by a '-',
  # and that they are numbered from 1 to n_options (4 in the example).
  # Also, the "incorrect" option of the couple should go first in each pair.
  
  # mean_options : Mean reward for each option.
  # The length should correspond to n_options.
  
  # sd_options : SD reward for each option.
  # The length should correspond to n_options.
  
  generate_trial_type_sequence <- function (n_trials, trial_types) {
    n_trial_types = length(trial_types)
    sequence = rep(trial_types, n_trials/n_trial_types)
    sample(sequence)
    
    count = 3
    while (count < length(sequence)) {
      if (sequence[count]==sequence[count-1] & sequence[count-1]==sequence[count-2]) {
        sample(sequence)
        count = 2
      }
      count = count + 1
    }
    return(sequence)
  }
  
  task_design = data.frame(
    trial = seq(1, n_trials),
    trial_type = generate_trial_type_sequence(n_trials, trial_types)
    )
  
  task_design <- separate(task_design, 
                          col=trial_type,
                          into=c('inc_option', 'cor_option'),
                          sep='-',
                          remove=FALSE,
                          convert=TRUE)

  options = unique(c(unique(task_design$inc_option), unique(task_design$cor_option)))
  n_options = length(options)
  print("The task will be created with the following options:")
  print(data.frame(options=options, mean=mean_options, sd=sd_options))
  
  task_design$f_inc = round(rnorm(
    mean = mean_options[task_design$inc_option], 
    sd = sd_options[task_design$inc_option], 
    n=dim(task_design)[1]))
  task_design$f_cor = round(rnorm(
    mean = mean_options[task_design$cor_option], 
    sd = sd_options[task_design$cor_option], 
    n=dim(task_design)[1]))
  
  return(task_design)
}
```

Generate a bunch of trials and visualize the task design:
```{r echo=TRUE, message=FALSE, warning=FALSE}
stimuli <- generate_RL_stimuli(
  n_trials=200,
  trial_types=c('1-2', '1-3', '2-4', '3-4'),
  mean_options=c(30, 34, 50, 54),
  sd_options=c(5, 5, 5, 5))

head(stimuli)

stimuli_for_plotting <- pivot_longer(stimuli, cols=c(f_inc, f_cor), names_to = "option", names_prefix = "f_", values_to="feedback")

ggplot(data = stimuli_for_plotting, aes(x = trial, y = feedback, color=option))+
  geom_line(size = .5) +
  geom_point() +
  facet_grid(rows = vars(trial_type))
```

We can now write down Equations 1, 4, and 5 from [our RLDM paper](https://link.springer.com/article/10.3758/s13423-018-1554-2) to simulate the process described by the RLDM:

```{r echo=TRUE}
# simulate data from simple DM
random_dm <- function(drift, threshold, ndt, rel_sp=.5, noise_constant=1, dt=0.001, max_rt=10) {
  
  if (length(drift) != length(threshold) | length(threshold)!=length(ndt)) {
    stop("drift, threshold, and ndt should have the same length")
  }
  
  n_trials <- length(drift)
  acc <- rep(NA, n_trials)
  rt <- rep(NA, n_trials)
  max_tsteps <- max_rt/dt
  
  # initialize the diffusion process
  tstep <- 0
  x <- rel_sp*threshold # vector of accumulated evidence at t=tstep
  ongoing <- rep(TRUE, n_trials) # have the accumulators reached the bound?
  
  # start accumulating
  while (sum(ongoing) > 0 & tstep < max_tsteps) {
    x[ongoing] <- x[ongoing] + rnorm(mean=drift[ongoing]*dt,
                                     sd=noise_constant*sqrt(dt),
                                     n=sum(ongoing))
    tstep <- tstep + 1
    
    # ended trials
    ended_correct <- (x >= threshold)
    ended_incorrect <- (x <= 0)
    
    # store results and filter out ended trials
    if(sum(ended_correct) > 0) {
      acc[ended_correct & ongoing] <- 1
      rt[ended_correct & ongoing] <- dt*tstep + ndt[ended_correct & ongoing]
      ongoing[ended_correct] <- FALSE
    }
    
    if(sum(ended_incorrect) > 0) {
      acc[ended_incorrect & ongoing] <- 0
      rt[ended_incorrect & ongoing] <- dt*tstep + ndt[ended_incorrect & ongoing]
      ongoing[ended_incorrect] <- FALSE
    }
  }
  return (data.frame(trial=seq(1, n_trials), accuracy=acc, rt=rt))
}

# simulate data from simple RLDM
random_rldm <- function(stimuli, alpha, drift_scaling, threshold, ndt, rel_sp=.5, noise_constant=1, dt=0.001, max_rt=10, initial_value_learning=20) {
  n_trials = dim(stimuli)[1]
  options = unique(c(unique(stimuli$inc_option), unique(stimuli$cor_option)))
  n_options = length(options)
  
  # Rescorla Wagner learning rule
  stimuli$Q_cor = NA
  stimuli$Q_inc = NA
  Q = rep(initial_value_learning, n_options)
  
  for (n in seq(1, n_trials, 1)) {
    index_cor = stimuli[n, "cor_option"]
    index_inc = stimuli[n, "inc_option"]
    
    # current expectations
    stimuli[n, "Q_cor"] = Q[index_cor]
    stimuli[n, "Q_inc"] = Q[index_inc]
    
    # update expectations
    Q[index_cor] = Q[index_cor] + alpha*(stimuli[n, "f_cor"] - Q[index_cor])
    Q[index_inc] = Q[index_inc] + alpha*(stimuli[n, "f_inc"] - Q[index_inc])
  }
  
  # Diffusion Model as decision rule
  stimuli$drift = drift_scaling*(stimuli$Q_cor - stimuli$Q_inc)
  stimuli$threshold = threshold
  stimuli$ndt = ndt
  
  performance = random_dm(stimuli$drift, stimuli$threshold, stimuli$ndt)
  
  return(cbind(stimuli, performance[,c("accuracy", "rt")]))
}
```

And use it to simulate data using the previously generated stimuli:
```{r echo=TRUE, message=FALSE, warning=FALSE}
sim_data <- random_rldm(stimuli, alpha = .03, drift_scaling = .1, threshold = 1.2, ndt=.15)

head(sim_data)
```

First, we can have a look at the average performance across trial-types. Note that, since the threshold was not modulated, the same performance is predicted across magnitudes:
```{r echo=TRUE, message=FALSE, warning=FALSE}
sim_data$trial_bin <- cut(sim_data$trial,
                          breaks = seq(min(sim_data$trial), max(sim_data$trial), length.out=7),
                          include.lowest = TRUE)

ggplot(data = sim_data, aes(x = trial_type, y = rt,  color=trial_type))+
  stat_summary(fun = "mean", geom="point", size=4) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar",  size=.3, width=.3)

ggplot(data = sim_data, aes(x = trial_type, y = accuracy, color=trial_type))+
  stat_summary(fun = "mean", geom="point", size=4) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar",  size=.3, width=.3)
```

While we kept both the threshold and ndt fixed, the drift-rates evolves with learning:
```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = sim_data, aes(x = trial, y = drift, color=trial_type))+
  geom_line(size = .5) +
  geom_point()
```

Therefore, we expect the accuracy and RTs to also improve with learning:
```{r echo=TRUE, message=FALSE, warning=FALSE}
sim_data$trial_bin <- cut(sim_data$trial,
                          breaks = seq(min(sim_data$trial), max(sim_data$trial), length.out=7),
                          include.lowest = TRUE)

ggplot(data = sim_data, aes(x = trial_bin, y = rt))+
  geom_violin(draw_quantiles = c(0.1, 0.5, 0.9))

ggplot(data = sim_data, aes(x = trial_bin, y = accuracy))+
    stat_summary(fun = "mean", geom="bar", position = 'dodge') +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar",  size=.2, width=.9, position = 'dodge')
```

## Parameter recovery with MLE

To get the likelihood of the RLDM, we can build on the likelihood of the DM (that we saw in the previous lecture):
```{r echo=TRUE, message=TRUE, warning=TRUE}
log_likelihood_rldm <- function(par, data, initial_value_learning=20, ll_threshold=1e-10) {
  # par order: alpha, drift_scaling, threshold, ndt
  
  n_trials = dim(data)[1]
  options = unique(c(unique(data$inc_option), unique(data$cor_option)))
  n_options = length(options)
  
  # Rescorla Wagner learning rule
  data$Q_cor = NA
  data$Q_inc = NA
  Q = rep(initial_value_learning, n_options)
  
  for (n in seq(1, n_trials, 1)) {
    index_cor = data[n, "cor_option"]
    index_inc = data[n, "inc_option"]
    
    # current expectations
    data[n, "Q_cor"] = Q[index_cor]
    data[n, "Q_inc"] = Q[index_inc]
    
    # update expectations
    Q[index_cor] = Q[index_cor] + par[1]*(data[n, "f_cor"] - Q[index_cor])
    Q[index_inc] = Q[index_inc] + par[1]*(data[n, "f_inc"] - Q[index_inc])
  }
  
  # Diffusion Model as decision rule
  drift <- par[2]*(data$Q_cor - data$Q_inc)
  density <- ddiffusion(rt=data$rt, response=data$response, a=par[3], v=drift, t0=par[4])
  
  density[density <= ll_threshold] = ll_threshold # put a threhsold on very low likelihoods for computability
  
  return(sum(log(density)))
}
```

We can thus use the Nelder-Mead algorithm in the `dfoptim` package to estimate the parameters:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# preparing the data for the likelihood func
sim_data$response = "lower"
sim_data[sim_data$accuracy == 1, "response"] = "upper"

starting_values = c(.5, .1, 2, .2) # set some starting values

print(log_likelihood_rldm(starting_values, data=sim_data)) # check that starting values are plausible

fit1 <- nmkb(par = starting_values,
             fn = function (x) log_likelihood_rldm(x, data=sim_data),
             lower = c(0, -10, 0, 0),
             upper = c(1, 10, 10, 5),
             control = list(maximize = TRUE))
print(fit1$par) # print estimated parameters
```

## Parameter Recovery with stan

We can also recover the generating parameters of the simulated data with stan, to assess th model's identifialbility.

First, we need to prepare our data for stan:

```{r message=FALSE, warning=FALSE}
sim_data$accuracy_recoded = sim_data$accuracy
sim_data[sim_data$accuracy==0, "accuracy_recoded"] = -1

sim_data_for_stan = list(
  N = dim(sim_data)[1],
  K = 4, # n options
  accuracy = sim_data$accuracy_recoded,
  rt = sim_data$rt,
  starting_point = 0.5,
  initial_value=20,
  f_cor=sim_data$f_cor,
  f_inc=sim_data$f_inc,
  trial=sim_data$trial,
  cor_option=sim_data$cor_option,
  inc_option=sim_data$inc_option
)
```

And then we can fit the model:

```{r message=FALSE, warning=FALSE}
fit1 <- stan(
  file = "stan_models/RLDM.stan",                    # Stan program
  data = sim_data_for_stan,                          # named list of data
  chains = 2,                                        # number of Markov chains
  warmup = 1000,                                     # number of warmup iterations per chain
  iter = 3000,                                       # total number of iterations per chain
  cores = 2                                          # number of cores (could use one per chain)
)
```

Compare the generating parameters with the recovered ones and check for convergence looking at the Rhat measures:

```{r echo=TRUE, message=FALSE, warning=FALSE}
print(fit1, pars = c("transf_alpha", "transf_drift_scaling", "transf_threshold", "transf_ndt"))
```

And (visually) assess the model's convergence as well as some more sampling diagnostics:
```{r echo=TRUE, message=FALSE, warning=FALSE}
traceplot(fit1, pars = c("transf_alpha", "transf_drift_scaling", "transf_threshold", "transf_ndt"), 
          inc_warmup = FALSE, nrow = 2)

sampler_params <- get_sampler_params(fit1, inc_warmup = TRUE)
summary(do.call(rbind, sampler_params), digits = 2)
```

More plotting:
```{r}
posterior <- as.matrix(fit1)

plot_title <- ggtitle("Posterior distributions",
                      "with medians and 95% intervals")
mcmc_areas(posterior,
           pars = c("transf_alpha", "transf_drift_scaling", "transf_threshold", "transf_ndt"),
           prob = 0.95) + plot_title
```